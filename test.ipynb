{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing odia train data...\n",
      "Processing odia test_known data...\n",
      "Processing odia test_known data...\n",
      "Processing malayalam train data...\n",
      "Processing malayalam test_known data...\n",
      "Processing malayalam test_known data...\n",
      "Processing marathi train data...\n",
      "Processing marathi test_known data...\n",
      "Processing marathi test_known data...\n",
      "Processing sanskrit train data...\n",
      "Processing sanskrit test_known data...\n",
      "Processing sanskrit test_known data...\n",
      "Processing kannada train data...\n",
      "Processing kannada test_known data...\n",
      "Processing kannada test_known data...\n",
      "Processing bengali train data...\n",
      "Processing bengali test_known data...\n",
      "Processing bengali test_known data...\n",
      "Processing tamil train data...\n",
      "Processing tamil test_known data...\n",
      "Processing tamil test_known data...\n",
      "Processing telugu train data...\n",
      "Processing telugu test_known data...\n",
      "Processing telugu test_known data...\n",
      "Processing urdu train data...\n",
      "Processing urdu test_known data...\n",
      "Processing urdu test_known data...\n",
      "Processing punjabi train data...\n",
      "Processing punjabi test_known data...\n",
      "Processing punjabi test_known data...\n",
      "Processing hindi train data...\n",
      "Processing hindi test_known data...\n",
      "Processing hindi test_known data...\n",
      "Processing gujarati train data...\n",
      "Processing gujarati test_known data...\n",
      "Processing gujarati test_known data...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# test_audio = \"testkn_audio/kb_data_clean_m4a/tamil/test_known/audio\"\n",
    "# train_val_audio = \"train_audio/kb_data_clean_m4a/sanskrit/train/audio\" # train, valid\n",
    "# transcript_files = \"transcripts_n2w/kb_data_clean_m4a/tamil/train/transcription_n2w.txt\" # test_known, test, valid, train\n",
    "\n",
    "\n",
    "# noisy_audio = \"noisy/testkn_audio/kb_data_noisy_m4a/tamil/test_known/audio\" # test_known\n",
    "# noisy_transcription_files = \"noisy/kb_data_noisy_m4a/tamil/test_known\" # test_known, test, valid\n",
    "\n",
    "\n",
    "test_audio = \"../raw_indiaai_dataset/testkn_audio/kb_data_clean_m4a/\"\n",
    "train_audio = \"../raw_indiaai_dataset/train_audio/kb_data_clean_m4a/\"\n",
    "val_audio = \"../raw_indiaai_dataset/train_audio/kb_data_clean_m4a/\" \n",
    "transcript_files = \"../raw_indiaai_dataset/transcripts_n2w/kb_data_clean_m4a\" # test_known, test, valid, train\n",
    "\n",
    "\n",
    "noisy_audio = \"../raw_indiaai_dataset/noisy/testkn_audio/kb_data_noisy_m4a/\" # test_known\n",
    "noisy_transcription_files = \"../raw_indiaai_dataset/noisy/kb_data_noisy_m4a\" # test_known, test, valid\n",
    "\n",
    "\n",
    "\n",
    "train_path = {}\n",
    "test_path = {}\n",
    "noisy_test_path = {}\n",
    "\n",
    "check_if_exists = True\n",
    "\n",
    "for lang in os.listdir(test_audio):\n",
    "    for dict_, audio_path, transcript_path, type_ in zip(\n",
    "        [train_path, test_path, noisy_test_path],\n",
    "        [train_audio, test_audio, noisy_audio],\n",
    "        [transcript_files, transcript_files, noisy_transcription_files],\n",
    "        [\"train\", \"test_known\", \"test_known\"],\n",
    "    ):\n",
    "        print(f\"Processing {lang} {type_} data...\")\n",
    "        audio_path = os.path.join(audio_path, lang, type_, \"audio\")\n",
    "        dict_[lang] = {}\n",
    "        dict_[lang][\"audio\"] = sorted([os.path.join(audio_path, file) for file in os.listdir(audio_path)])\n",
    "        transcript = os.path.join(transcript_path, lang, type_, \"transcription_n2w.txt\")\n",
    "        dict_[lang][\"transcript\"] = {}\n",
    "        for i in open(transcript, 'r').readlines():\n",
    "            k, v = tuple(i.lstrip().rstrip().split('\\t'))\n",
    "            dict_[lang][\"transcript\"][os.path.join(audio_path, k)] = v\n",
    "            \n",
    "        count = 0\n",
    "        if check_if_exists:\n",
    "            for i in dict_[lang][\"audio\"]:\n",
    "                if i not in dict_[lang][\"transcript\"]:\n",
    "                    print(f\"Audio file {i} not found in transcript.\")\n",
    "                    count+=1\n",
    "                    \n",
    "        # print(f\"Total {count} files not found in transcript.\")\n",
    "            \n",
    "            \n",
    "            \n",
    "        \n",
    "        \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Assuming train_path, val_path, test_path, noisy_test_path are already populated\n",
    "\n",
    "# def get_audio_counts(data_dict):\n",
    "#     counts = {}\n",
    "#     for lang, data in data_dict.items():\n",
    "#         counts[lang] = len(data['audio'])\n",
    "#     return counts\n",
    "\n",
    "# train_counts = get_audio_counts(train_path)\n",
    "# test_counts = get_audio_counts(test_path)\n",
    "# noisy_test_counts = get_audio_counts(noisy_test_path)\n",
    "\n",
    "# langs = sorted(set(train_counts) | set(test_counts) | set(noisy_test_counts))\n",
    "\n",
    "# # Plot 1: Train / Val / Test / Noisy Test Counts\n",
    "# x = range(len(langs))\n",
    "# bar_width = 0.2\n",
    "\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# plt.bar([i - 1.5 * bar_width for i in x], [train_counts.get(lang, 0) for lang in langs], width=bar_width, label='Train')\n",
    "# plt.bar([i + 0.5 * bar_width for i in x], [test_counts.get(lang, 0) for lang in langs], width=bar_width, label='Test')\n",
    "# plt.bar([i + 1.5 * bar_width for i in x], [noisy_test_counts.get(lang, 0) for lang in langs], width=bar_width, label='Noisy Test')\n",
    "\n",
    "# plt.xlabel('Languages')\n",
    "# plt.ylabel('Number of Audio Files')\n",
    "# plt.title('Audio File Count per Language and Data Split')\n",
    "# plt.xticks(ticks=x, labels=langs)\n",
    "# plt.legend()\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "# # Plot 2: Raw vs Noisy (Test Only)\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# x = range(len(langs))\n",
    "# plt.bar([i - 0.2 for i in x], [test_counts.get(lang, 0) for lang in langs], width=0.4, label='Raw Test')\n",
    "# plt.bar([i + 0.2 for i in x], [noisy_test_counts.get(lang, 0) for lang in langs], width=0.4, label='Noisy Test')\n",
    "\n",
    "# plt.xlabel('Languages')\n",
    "# plt.ylabel('Number of Test Audio Files')\n",
    "# plt.title('Raw vs Noisy Test Audio Counts per Language')\n",
    "# plt.xticks(ticks=x, labels=langs)\n",
    "# plt.legend()\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 1000 noisy train\n",
    "# # 6200 train\n",
    "\n",
    "# # 200 val (from train since val path is empty)\n",
    "# # 200 noisy (from noisy test)\n",
    "\n",
    "# # 200 test\n",
    "# # 200 noisy test (from noisy test)\n",
    "\n",
    "# nosiy_train_set = {}\n",
    "# nosiy_test_set = {}\n",
    "# noisy_val_set = {}\n",
    "\n",
    "# for lang in noisy_test_path:\n",
    "#     nosiy_train_set[lang] = {}\n",
    "#     nosiy_test_set[lang] = {}\n",
    "#     noisy_val_set[lang] = {}\n",
    "#     nosiy_train_set[lang][\"audio\"] = noisy_test_path[lang][\"audio\"][:1000]\n",
    "#     nosiy_train_set[lang][\"transcript\"] = noisy_test_path[lang][\"transcript\"]\n",
    "#     nosiy_test_set[lang][\"audio\"] = noisy_test_path[lang][\"audio\"][1000:1200]\n",
    "#     nosiy_test_set[lang][\"transcript\"] = noisy_test_path[lang][\"transcript\"]\n",
    "#     noisy_val_set[lang][\"audio\"] = noisy_test_path[lang][\"audio\"][1200:1400]\n",
    "#     noisy_val_set[lang][\"transcript\"] = noisy_test_path[lang][\"transcript\"]\n",
    "    \n",
    "# train_set = {}\n",
    "# val_set = {}\n",
    "\n",
    "# for lang in train_path:\n",
    "#     train_set[lang] = {}\n",
    "#     val_set[lang] = {}\n",
    "#     train_set[lang][\"audio\"] = train_path[lang][\"audio\"][:6200]\n",
    "#     train_set[lang][\"transcript\"] = train_path[lang][\"transcript\"]\n",
    "#     val_set[lang][\"audio\"] = train_path[lang][\"audio\"][6200:6400]\n",
    "#     val_set[lang][\"transcript\"] = train_path[lang][\"transcript\"]\n",
    "    \n",
    "# test_set = {}\n",
    "# for lang in test_path:\n",
    "#     test_set[lang] = {}\n",
    "#     test_set[lang][\"audio\"] = test_path[lang][\"audio\"][:200]\n",
    "#     test_set[lang][\"transcript\"] = test_path[lang][\"transcript\"]\n",
    "   \n",
    "# ### merge nosiy train and train\n",
    "# for lang in train_set:\n",
    "#     nosiy_train_set[lang][\"audio\"] += train_set[lang][\"audio\"]\n",
    "#     nosiy_train_set[lang][\"transcript\"].update(train_set[lang][\"transcript\"])\n",
    "    \n",
    "# import pickle\n",
    "# with open(\"dataset.pkl\", \"wb\") as f:\n",
    "#     pickle.dump({\n",
    "#         \"train\": nosiy_train_set,\n",
    "#         \"val\": val_set,\n",
    "#         \"test\": test_set,\n",
    "#         \"noisy_val\": noisy_val_set,\n",
    "#         \"noisy_test\": nosiy_test_set\n",
    "#     }, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds = pickle.load(open(\"dataset.pkl\", \"rb\"))\n",
    "# for v in ds.values():\n",
    "#     print(get_audio_counts(v))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### copy all the audio files to this path: /home/frozenwolf/Desktop/indiaai_subset\n",
    "# import shutil\n",
    "# import os\n",
    "# from tqdm.auto import tqdm\n",
    "\n",
    "# def copy_files(data_dict, base_path):\n",
    "#     for lang, data in tqdm(data_dict.items()):\n",
    "#         lang_path = os.path.join(base_path, lang)\n",
    "#         os.makedirs(lang_path, exist_ok=True)\n",
    "#         for audio_file in data['audio']:\n",
    "#             shutil.copy(audio_file, lang_path)\n",
    "\n",
    "# copy_files(nosiy_train_set, \"/home/frozenwolf/Desktop/indiaai_subset/train\")\n",
    "# copy_files(val_set, \"/home/frozenwolf/Desktop/indiaai_subset/val\")\n",
    "# copy_files(test_set, \"/home/frozenwolf/Desktop/indiaai_subset/test\")\n",
    "# copy_files(noisy_val_set, \"/home/frozenwolf/Desktop/indiaai_subset/val\")\n",
    "# copy_files(nosiy_test_set, \"/home/frozenwolf/Desktop/indiaai_subset/test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# dataset = pickle.load(open(\"dataset.pkl\", \"rb\"))\n",
    "# for ds in dataset.keys():\n",
    "#     for lang in dataset[ds]:\n",
    "#         for idx in range(len(dataset[ds][lang][\"audio\"])):\n",
    "#             dataset[ds][lang][\"audio\"][idx] = dataset[ds][lang][\"audio\"][idx].split(\"/\")[-1]\n",
    "            \n",
    "#         ### modify transcript key:\n",
    "#         dataset[ds][lang][\"transcript\"] = {i.split(\"/\")[-1]: dataset[ds][lang][\"transcript\"][i] for i in dataset[ds][lang][\"transcript\"]}\n",
    "        \n",
    "# pickle.dump(dataset, open(\"dataset.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# dataset = pickle.load(open(\"../dataset.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EncDecHybridRNNTCTCBPEModel(\n",
       "  (preprocessor): AudioToMelSpectrogramPreprocessor(\n",
       "    (featurizer): FilterbankFeatures()\n",
       "  )\n",
       "  (encoder): ConformerEncoder(\n",
       "    (pre_encode): ConvSubsampling(\n",
       "      (out): Linear(in_features=10240, out_features=512, bias=True)\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(1, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (3): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (pos_enc): RelPositionalEncoding(\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (layers): ModuleList(\n",
       "      (0-16): 17 x ConformerLayer(\n",
       "        (norm_feed_forward1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (feed_forward1): ConformerFeedForward(\n",
       "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (activation): Swish()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (norm_conv): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (conv): ConformerConvolution(\n",
       "          (pointwise_conv1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "          (depthwise_conv): CausalConv1D(512, 512, kernel_size=(31,), stride=(1,), groups=512)\n",
       "          (batch_norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activation): Swish()\n",
       "          (pointwise_conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (norm_self_att): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (self_attn): RelPositionMultiHeadAttention(\n",
       "          (linear_q): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (linear_k): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (linear_v): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (linear_out): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear_pos): Linear(in_features=512, out_features=512, bias=False)\n",
       "        )\n",
       "        (norm_feed_forward2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (feed_forward2): ConformerFeedForward(\n",
       "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (activation): Swish()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (norm_out): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): RNNTDecoder(\n",
       "    (prediction): ModuleDict(\n",
       "      (embed): Embedding(5633, 640, padding_idx=5632)\n",
       "      (dec_rnn): LSTMDropout(\n",
       "        (lstm): LSTM(640, 640, dropout=0.2)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (joint): RNNTJoint(\n",
       "    (pred): Linear(in_features=640, out_features=640, bias=True)\n",
       "    (enc): Linear(in_features=512, out_features=640, bias=True)\n",
       "    (joint_net): Sequential(\n",
       "      (0): ReLU(inplace=True)\n",
       "      (1): Dropout(p=0.2, inplace=False)\n",
       "      (2): ModuleDict(\n",
       "        (as): Linear(in_features=640, out_features=257, bias=True)\n",
       "        (bn): Linear(in_features=640, out_features=257, bias=True)\n",
       "        (brx): Linear(in_features=640, out_features=257, bias=True)\n",
       "        (doi): Linear(in_features=640, out_features=257, bias=True)\n",
       "        (kok): Linear(in_features=640, out_features=257, bias=True)\n",
       "        (gu): Linear(in_features=640, out_features=257, bias=True)\n",
       "        (hi): Linear(in_features=640, out_features=257, bias=True)\n",
       "        (kn): Linear(in_features=640, out_features=257, bias=True)\n",
       "        (ks): Linear(in_features=640, out_features=257, bias=True)\n",
       "        (mai): Linear(in_features=640, out_features=257, bias=True)\n",
       "        (ml): Linear(in_features=640, out_features=257, bias=True)\n",
       "        (mr): Linear(in_features=640, out_features=257, bias=True)\n",
       "        (mni): Linear(in_features=640, out_features=257, bias=True)\n",
       "        (ne): Linear(in_features=640, out_features=257, bias=True)\n",
       "        (or): Linear(in_features=640, out_features=257, bias=True)\n",
       "        (pa): Linear(in_features=640, out_features=257, bias=True)\n",
       "        (sa): Linear(in_features=640, out_features=257, bias=True)\n",
       "        (sat): Linear(in_features=640, out_features=257, bias=True)\n",
       "        (sd): Linear(in_features=640, out_features=257, bias=True)\n",
       "        (ta): Linear(in_features=640, out_features=257, bias=True)\n",
       "        (te): Linear(in_features=640, out_features=257, bias=True)\n",
       "        (ur): Linear(in_features=640, out_features=257, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (_loss): RNNTLoss(\n",
       "      (_loss): RNNTLossNumba()\n",
       "    )\n",
       "    (_wer): WER()\n",
       "  )\n",
       "  (loss): RNNTLoss(\n",
       "    (_loss): RNNTLossNumba()\n",
       "  )\n",
       "  (spec_augmentation): SpectrogramAugmentation(\n",
       "    (spec_augment): SpecAugment()\n",
       "  )\n",
       "  (wer): WER()\n",
       "  (ctc_decoder): ConvASRDecoder(\n",
       "    (decoder_layers): Sequential(\n",
       "      (0): Conv1d(512, 5633, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "  )\n",
       "  (ctc_loss): CTCLoss()\n",
       "  (ctc_wer): WER()\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-04-20 21:09:14 mixins:198] _setup_tokenizer: detected an aggregate tokenizer\n",
      "[NeMo I 2025-04-20 21:09:14 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
      "[NeMo I 2025-04-20 21:09:14 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
      "[NeMo I 2025-04-20 21:09:14 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
      "[NeMo I 2025-04-20 21:09:14 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
      "[NeMo I 2025-04-20 21:09:14 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
      "[NeMo I 2025-04-20 21:09:14 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
      "[NeMo I 2025-04-20 21:09:14 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
      "[NeMo I 2025-04-20 21:09:14 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
      "[NeMo I 2025-04-20 21:09:14 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
      "[NeMo I 2025-04-20 21:09:14 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
      "[NeMo I 2025-04-20 21:09:14 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
      "[NeMo I 2025-04-20 21:09:14 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
      "[NeMo I 2025-04-20 21:09:14 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
      "[NeMo I 2025-04-20 21:09:14 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
      "[NeMo I 2025-04-20 21:09:14 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
      "[NeMo I 2025-04-20 21:09:14 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
      "[NeMo I 2025-04-20 21:09:14 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
      "[NeMo I 2025-04-20 21:09:14 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
      "[NeMo I 2025-04-20 21:09:14 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
      "[NeMo I 2025-04-20 21:09:14 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
      "[NeMo I 2025-04-20 21:09:14 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
      "[NeMo I 2025-04-20 21:09:14 mixins:335] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
      "[NeMo I 2025-04-20 21:09:14 multilingual_tokenizer:61] Aggregate vocab size: 5632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-04-20 21:09:20 modelPT:165] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    manifest_filepath:\n",
      "    - /nlsasfs/home/ai4bharat/ai4bharat-pr/speechteam/indicasr_v3/manifests/nemo/vistaar_v3/train/train_tamil.json\n",
      "    sample_rate: 16000\n",
      "    batch_size: 8\n",
      "    shuffle: false\n",
      "    num_workers: 16\n",
      "    pin_memory: true\n",
      "    max_duration: 30.0\n",
      "    min_duration: 0.2\n",
      "    is_tarred: false\n",
      "    tarred_audio_filepaths: null\n",
      "    shuffle_n: 2048\n",
      "    bucketing_strategy: synced_randomized\n",
      "    bucketing_batch_size: null\n",
      "    is_concat: true\n",
      "    concat_sampling_technique: temperature\n",
      "    concat_sampling_temperature: 1.5\n",
      "    return_language_id: true\n",
      "    \n",
      "[NeMo W 2025-04-20 21:09:20 modelPT:172] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    manifest_filepath:\n",
      "    - /nlsasfs/home/ai4bharat/ai4bharat-pr/speechteam/indicasr_v3/manifests/nemo/vistaar_v3/valid_datasetwise/valid_tamil_indicvoices.json\n",
      "    sample_rate: 16000\n",
      "    batch_size: 16\n",
      "    shuffle: false\n",
      "    use_start_end_token: false\n",
      "    num_workers: 8\n",
      "    return_language_id: true\n",
      "    pin_memory: true\n",
      "    \n",
      "[NeMo W 2025-04-20 21:09:20 modelPT:178] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
      "    Test config : \n",
      "    manifest_filepath: null\n",
      "    sample_rate: 16000\n",
      "    batch_size: 16\n",
      "    shuffle: false\n",
      "    use_start_end_token: false\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-04-20 21:09:20 features:289] PADDING: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frozenwolf/miniconda3/envs/indiaai/lib/python3.10/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-04-20 21:09:22 rnnt:1696] Vocab size for each language: 256\n",
      "[NeMo I 2025-04-20 21:09:22 rnnt_models:220] Using RNNT Loss : warprnnt_numba\n",
      "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n",
      "[NeMo I 2025-04-20 21:09:22 rnnt_models:220] Using RNNT Loss : warprnnt_numba\n",
      "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n",
      "[NeMo I 2025-04-20 21:09:23 rnnt_models:220] Using RNNT Loss : warprnnt_numba\n",
      "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n",
      "[NeMo I 2025-04-20 21:09:23 hybrid_rnnt_ctc_bpe_models:105] Creating masks for multi-softmax layer.\n",
      "[NeMo I 2025-04-20 21:09:23 rnnt_models:220] Using RNNT Loss : warprnnt_numba\n",
      "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n",
      "[NeMo I 2025-04-20 21:09:24 save_restore_connector:263] Model EncDecHybridRNNTCTCBPEModel was successfully restored from /home/frozenwolf/.cache/huggingface/hub/models--ai4bharat--indicconformer_stt_ta_hybrid_rnnt_large/snapshots/8c31aa8d04964b8fc87e4eaaee7916f7d2c024da/indicconformer_stt_ta_hybrid_rnnt_large.nemo.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='librosa')\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module='librosa')\n",
    "\n",
    "import NeMo.nemo.collections.asr as nemo_asr\n",
    "\n",
    "model = nemo_asr.models.ASRModel.from_pretrained(\"ai4bharat/indicconformer_stt_ta_hybrid_rnnt_large\")\n",
    "model.ctc_wer.log_prediction = False\n",
    "model.wer.log_prediction = False\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model.freeze() # inference mode\n",
    "model = model.to(device) # transfer model to device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from NeMo.nemo.core.classes.mixins import AccessMixin\n",
    "AccessMixin.is_access_enabled(model.model_guid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"multisoftmax\" not in model.cfg.decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model._optim_normalize_joint_txu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not model.is_interctc_enabled() or not AccessMixin.is_access_enabled(getattr(model, \"model_guid\", None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio = train_path['tamil']['audio'][:10]\n",
    "trasncripts = [train_path['tamil']['transcript'][i] for i in audio]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Manifest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 40880.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Dataloader\n",
      "[NeMo I 2025-04-20 15:51:48 collections:196] Dataset loaded with 10 files totalling 0.00 hours\n",
      "[NeMo I 2025-04-20 15:51:48 collections:197] 0 files were filtered totalling 0.00 hours\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "###inference \n",
    "# model.cur_decoder = \"rnnt\"\n",
    "# ctc_text = model.transcribe(audio, batch_size=10,logprobs=True, language_id='ta')\n",
    "# print(ctc_text)\n",
    "\n",
    "\n",
    "### train dataloader:\n",
    "import tempfile\n",
    "\n",
    "from NeMo.nemo.collections.asr.models.hybrid_rnnt_ctc_models import TranscribeConfig, InternalTranscribeConfig\n",
    "\n",
    "transcribe_cfg = TranscribeConfig(\n",
    "                batch_size=12,\n",
    "                return_hypotheses=False,\n",
    "                num_workers=0,\n",
    "                channel_selector=None,\n",
    "                augmentor=None,\n",
    "                verbose=True,\n",
    "                logprobs=True,\n",
    "                language_id='ta',\n",
    "            )\n",
    "\n",
    "transcribe_cfg._internal = InternalTranscribeConfig()\n",
    "\n",
    "tmpdir = tempfile.mkdtemp()\n",
    "transcribe_cfg._internal.temp_dir = tmpdir\n",
    "dataloader = model._transcribe_input_processing(audio, transcribe_cfg, trasncripts)\n",
    "    \n",
    "\n",
    "def move_to_device(batch, device):\n",
    "    \"\"\"\n",
    "    Recursively move all tensors in `batch` to `device`.\n",
    "    \"\"\"\n",
    "    if isinstance(batch, torch.Tensor):\n",
    "        return batch.to(device)\n",
    "    elif isinstance(batch, (list, tuple)):\n",
    "        return [move_to_device(x, device) for x in batch]\n",
    "    elif isinstance(batch, dict):\n",
    "        return {k: move_to_device(v, device) for k, v in batch.items()}\n",
    "    else:\n",
    "        raise TypeError(f\"Unsupported type: {type(batch)}\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcribe_cfg._internal.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trainable params: 129.250967M\n"
     ]
    }
   ],
   "source": [
    "### total trainable params\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total trainable params: {total_params/1e6}M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([10, 135977]),\n",
       " torch.Size([10]),\n",
       " torch.Size([10, 70]),\n",
       " torch.Size([10])]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch  = next(iter(dataloader))\n",
    "[i.shape for i in batch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.joint.fuse_loss_wer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([37, 49, 52, 33, 44, 70, 51, 37, 60, 43])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Freeze the first 6–8 encoder layers (more general)\n",
    "# from utils import save_model\n",
    "# save_model(model, \"test.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable params: 129.250967M\n"
     ]
    }
   ],
   "source": [
    "## print trainable params\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Trainable params: {trainable_params/1e6}M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params count:  129.250967\n",
      "Params count:  4.362774\n",
      "Params count:  115.111424\n"
     ]
    }
   ],
   "source": [
    "print(\"Params count: \", sum(p.numel() for p in model.parameters())/1e6)\n",
    "print(\"Params count: \", sum(p.numel() for p in model.joint.parameters())/1e6)\n",
    "print(\"Params count: \", sum(p.numel() for p in model.encoder.parameters())/1e6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.joint._fused_batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = move_to_device(batch, 'cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "model.joint.store_sub_enc = False\n",
    "model.joint.store_sub_logits = True\n",
    "model.ctc_decoder.return_logits_ = True\n",
    "model.joint.detach_sub_enc = False\n",
    "\n",
    "model.train()\n",
    "\n",
    "with torch.no_grad():\n",
    "    loss, montor = model.training_step(batch, ['ta']*len(batch[0]))  ## {'loss': tensor(233.4939, device='cuda:0')}\n",
    "    \n",
    "del batch, loss, montor\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9757.9961, device='cuda:0')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_logits = model.ctc_decoder.decoder_logits\n",
    "loss = (decoder_logits.flatten(end_dim=-2) ** 2).sum(dim=-1).mean()\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(torch.Size([4, 186, 53, 257]), device(type='cuda', index=0)),\n",
       " (torch.Size([4, 213, 71, 257]), device(type='cuda', index=0)),\n",
       " (torch.Size([2, 205, 61, 257]), device(type='cuda', index=0))]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnnt_store_list = model.joint.store_list\n",
    "[(i.shape, i.device) for i in rnnt_store_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(101675.6094, device='cuda:0')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_logits = 0\n",
    "\n",
    "for i in rnnt_store_list:\n",
    "    rnn_logits += (i.flatten(end_dim=-2) ** 2).sum(dim=-1).mean()\n",
    "\n",
    "rnn_logits = rnn_logits / len(rnnt_store_list)\n",
    "rnn_logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "model.joint.store_sub_enc = True\n",
    "model.joint.detach_sub_enc = True\n",
    "\n",
    "model.train()\n",
    "\n",
    "with torch.no_grad():\n",
    "    loss, montor, prob_ = model.training_step(batch, ['ta']*len(batch[0]), return_probs=True)  ## {'loss': tensor(233.4939, device='cuda:0')}\n",
    "    \n",
    "del batch, loss, montor\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(torch.Size([4, 186, 53, 257]), device(type='cuda', index=0)),\n",
       " (torch.Size([4, 213, 71, 257]), device(type='cuda', index=0)),\n",
       " (torch.Size([2, 205, 61, 257]), device(type='cuda', index=0))]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store_list = model.joint.store_list\n",
    "[(i.shape, i.device) for i in store_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch  = next(iter(dataloader), 2)\n",
    "batch = move_to_device(batch, 'cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.joint.store_sub_enc = True\n",
    "model.joint.detach_sub_enc = False\n",
    "\n",
    "model.train()\n",
    "\n",
    "loss, montor, prob = model.training_step(batch, ['ta']*len(batch[0]), return_probs=True)  ## {'loss': tensor(233.4939, device='cuda:0')}\n",
    "pred_store_list = model.joint.store_list\n",
    "\n",
    "del batch\n",
    "\n",
    "# loss.backward(retain_graph=True)\n",
    "# del loss\n",
    "# torch.cuda.empty_cache()\n",
    "\n",
    "prob_.to('cuda')\n",
    "\n",
    "kd_loss = torch.nn.functional.kl_div(\n",
    "    prob,  # input: log probabilities from student\n",
    "    prob_.exp(),  # target: probabilities from teacher\n",
    "    reduction='batchmean'\n",
    ")\n",
    "\n",
    "# kd_loss.backward(retain_graph=True)\n",
    "# del kd_loss\n",
    "# torch.cuda.empty_cache()\n",
    "\n",
    "kd_loss_ = 0\n",
    "assert len(store_list) == len(pred_store_list)\n",
    "for i,j in zip(store_list, pred_store_list):\n",
    "    i = i.to('cuda')\n",
    "    kd_loss_ += torch.nn.functional.kl_div(\n",
    "    j,  # input: log probabilities from student\n",
    "    i.exp(),  # target: probabilities from teacher\n",
    "    reduction='batchmean'\n",
    ")\n",
    "    \n",
    "# kd_loss.backward(retain_graph=True)\n",
    "# del kd_loss\n",
    "# torch.cuda.empty_cache()\n",
    "\n",
    "total_loss = kd_loss + kd_loss_ + loss\n",
    "total_loss.backward()\n",
    "\n",
    "\n",
    "### apply kl divergence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(device(type='cuda', index=0), device(type='cuda', index=0))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j.device, i.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(torch.Size([4, 186, 512]), device(type='cuda', index=0)),\n",
       " (torch.Size([4, 213, 512]), device(type='cuda', index=0)),\n",
       " (torch.Size([2, 205, 512]), device(type='cuda', index=0))]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(i.shape, i.device) for i in pred_store_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nemo.collections.asr.metrics.wer import WER\n",
    "\n",
    "wer = WER(\n",
    "            decoding=model.decoding,\n",
    "            batch_dim_index=0,\n",
    "            use_cer=model.cfg.get('use_cer', False),\n",
    "            log_prediction=False,\n",
    "            dist_sync_on_step=True,\n",
    "        )\n",
    "\n",
    "\n",
    "ctc_wer = WER(\n",
    "                    decoding=model.ctc_decoding,\n",
    "                    use_cer=model.ctc_wer.use_cer,\n",
    "                    log_prediction=False,\n",
    "                    dist_sync_on_step=True,\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-04-17 01:37:28 nemo_logging:349] /home/frozenwolf/Desktop/indiai/NeMo/nemo/collections/asr/parts/preprocessing/features.py:417: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "      with torch.cuda.amp.autocast(enabled=False):\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores: 0.0 hyp:  சீமான் மீதான புகார் குறித்து நடிகை விஜயலட்சுமி வீட்டில் போலீஸ் விசாரணை, ref:  சீமான் மீதான புகார் குறித்து நடிகை விஜயலட்சுமி வீட்டில் போலீஸ் விசாரணை\n",
      "scores: 0.2727272727272727 hyp:  தேர்தல் காலத்தில் தேர்தலுக்கு முன்பாக தேர்தலின் போது மற்றும் தேர்தல் நடந்து இருந்ததன் பின்னரான அறிக்கையிடலின், ref:  தேர்தல் காலத்தில் தேர்தலுக்கு முன்பாக தேர்தலின்போது மற்றும் தேர்தல் நடந்து முடிந்ததன் பின்னரான அறிக்கையிடலின்\n",
      "scores: 0.14285714285714285 hyp:  அமைச்சரவை பதவி ஏற்ற பின் யார் யாருக்கு இந்த இலக்கா என்பது குறித்த தகவல்கள் வெளிவரும் என்பது குறிப்பிடத்தக்கது, ref:  அமைச்சரவை பதவி ஏற்ற பின் யார் யாருக்கு எந்த இலாகா என்பது குறித்த தகவல்கள் வெளிவரும் என்பது குறிப்பிடத்தக்கது\n",
      "scores: 0.2222222222222222 hyp:  ஒரு படிமம் முன்னொன்றில் விட்டுப்போனதை நிறைக்கிறது என்று எனக்கும் இப்போது படுகிறது, ref:  ஒரு படிமம் இன்னொன்றில் விட்டுப்போனதை நிறைக்கிறது என எனக்கும் இப்போது படுகிறது\n",
      "scores: 0.1 hyp:  பரங்கிமலை ரயில் நிலையம் அருகே நிறுத்தி வைக்கப்பட்டிருந்த காவலரின் இருசக்கர வாகனம் திரட்டு, ref:  பரங்கிமலை ரயில் நிலையம் அருகே நிறுத்தி வைக்கப்பட்டிருந்த காவலரின் இருசக்கர வாகனம் திருட்டு\n",
      "scores: 0.38461538461538464 hyp:  அம்பிகாபதிக்கோவை என்ற தமிழ்நாடு பிற்காலத்தில் கம்பனுடனும் சோழர்களுடனும் இணைத்து புரிந்து கொண்டார்கள் என்று ஊகிப்பதே சரியாக இருக்கும், ref:  அம்பிகாபதிக்கோவை என்ற தமிழ்நூலைப் பிற்காலத்தில் கம்பனுடனும் சோழனுடனும் இணைத்துக் கதைகள் புனைந்துகொண்டார்கள் என்று ஊகிப்பதே சரியாக இருக்கும்\n",
      "scores: 0.3333333333333333 hyp:  பாகிஸ்தானில் உள்ள கிராச்சி பகுதியில் மழையின் தாக்கம் அதிகமாக இருப்பதால் சிறுபான்மை முகத்தில் தண்ணீர் அடிக்கப்படுகின்றது, ref:  பாகிஸ்தானில் உள்ள கராச்சி பகுதியில் வெயிலின் தாக்கம் அதிகமாக இருப்பதால் சிறுவனின் முகத்தில் தண்ணீர் அடிக்கப்படிகின்றது\n",
      "scores: 0.3333333333333333 hyp:  தாதா தா சி பால்கே விருது பெற்ற இயக்குனர் பாலச்சந்திரனுக்கு கருணாநிதி வாழ்த்து, ref:  தாதா சாகேப் பால்கே விருது பெற்ற இயக்குனர் பாலசந்தருக்கு கருணாநிதி வாழ்த்து\n",
      "scores: 0.15384615384615385 hyp:  புற்றுநோய்க்காக சிகிச்சை பெறும் மாணவியை பார்ப்பதற்காக லண்டன் சென்றிருந்த பாகிஸ்தான் முன்னாள் பிரதமர் நவாஸ் ஷெரீப் மற்றும், ref:  புற்றுநோய்க்காக சிகிச்சை பெறும் மனைவியை பார்ப்பதற்காக லண்டன் சென்றிருந்த பாகிஸ்தான் முன்னாள் பிரதமர் நவாஸ் ஷெரிப் மற்றும்\n",
      "scores: 0.2 hyp:  ராணுவ குழு மோதல் எதிரொலி சிகிச்சை பெற்ற மாணவர்கள் வைத்தியசாலையை விட்டு வெளியிட்டனர், ref:  மாணவ குழு மோதல் எதிரொலி சிகிச்சை பெற்ற மாணவர்கள் வைத்தியசாலையை விட்டு வெளியேறினர்\n",
      "loss_value: 14.335089683532715\n",
      "training_batch_wer_2: 0.21071943640708923\n",
      "scores: 0.0 hyp:  சீமான் மீதான புகார் குறித்து நடிகை விஜயலட்சுமி வீட்டில் போலீஸ் விசாரணை, ref:  சீமான் மீதான புகார் குறித்து நடிகை விஜயலட்சுமி வீட்டில் போலீஸ் விசாரணை\n",
      "scores: 0.36363636363636365 hyp:  தேர்தல் காலத்தில் தேர்தலுக்கு முன்பாக தேர்தலின் போது மற்றும் தேர்தல் நடந்து இருந்ததன் பின்னரான அறிக்கையிடலன், ref:  தேர்தல் காலத்தில் தேர்தலுக்கு முன்பாக தேர்தலின்போது மற்றும் தேர்தல் நடந்து முடிந்ததன் பின்னரான அறிக்கையிடலின்\n",
      "scores: 0.42857142857142855 hyp:  அமைச்சரம் பதவிேற்றபின் யார் யாருக்கு இந்த இத்க்கா என்பது குறித்த தகவல்கள் வெளிவரும் என்பது குறிப்பிடத்தக்கது, ref:  அமைச்சரவை பதவி ஏற்ற பின் யார் யாருக்கு எந்த இலாகா என்பது குறித்த தகவல்கள் வெளிவரும் என்பது குறிப்பிடத்தக்கது\n",
      "scores: 0.3333333333333333 hyp:  ஒரு படிமம் முன்னொன்றில் விட்டுப்போனதே நிறைக்கிறது என்று எனக்கும் இப்போது படுகிறது, ref:  ஒரு படிமம் இன்னொன்றில் விட்டுப்போனதை நிறைக்கிறது என எனக்கும் இப்போது படுகிறது\n",
      "scores: 0.1 hyp:  பரங்கிமலை ரயில் நிலையம் அருகே நிறுத்தி வைக்கப்பட்டிருந்த காவலரின் இருசக்கர வாகனம் திரீடு, ref:  பரங்கிமலை ரயில் நிலையம் அருகே நிறுத்தி வைக்கப்பட்டிருந்த காவலரின் இருசக்கர வாகனம் திருட்டு\n",
      "scores: 0.38461538461538464 hyp:  அம்பிகாபதிக்கோவை என்ற தமிழ்நழ பிற்காலத்தில் கம்பனுடனும் சோழனடனும் இணைத்துவளை புரிந்து கொண்டார்கள் என்று ஊகிப்பதே சரியாக இருக்கும், ref:  அம்பிகாபதிக்கோவை என்ற தமிழ்நூலைப் பிற்காலத்தில் கம்பனுடனும் சோழனுடனும் இணைத்துக் கதைகள் புனைந்துகொண்டார்கள் என்று ஊகிப்பதே சரியாக இருக்கும்\n",
      "scores: 0.3333333333333333 hyp:  பாகிஸ்தானில் உள்ள களாச்சி பகுதியில் மண்ணையின் தாக்கம் அதிகமாக இருப்பதால் சிறமின் முகத்தில் தண்ணீர் அடிக்கப்படுகின்றது, ref:  பாகிஸ்தானில் உள்ள கராச்சி பகுதியில் வெயிலின் தாக்கம் அதிகமாக இருப்பதால் சிறுவனின் முகத்தில் தண்ணீர் அடிக்கப்படிகின்றது\n",
      "scores: 0.4444444444444444 hyp:  த தாதா சாகி பால்கே விருது பெற்ற இயக்குனர்ர் பாலச்சந்திரக்கு கருணாநிதி வாழ்த்து, ref:  தாதா சாகேப் பால்கே விருது பெற்ற இயக்குனர் பாலசந்தருக்கு கருணாநிதி வாழ்த்து\n",
      "scores: 0.15384615384615385 hyp:  புற்றுநோய்க்காக சிகிச்சை பெறும் மாணவியை பார்ப்பதற்காக லண்டன் சென்றிருந்த பாகிஸ்தான் முன்னாள் பிரதமர் நவாஸ் ஷெரப் மற்றும், ref:  புற்றுநோய்க்காக சிகிச்சை பெறும் மனைவியை பார்ப்பதற்காக லண்டன் சென்றிருந்த பாகிஸ்தான் முன்னாள் பிரதமர் நவாஸ் ஷெரிப் மற்றும்\n",
      "scores: 0.5 hyp:  ராணுவ குழு மோதல் எதிரொலி சிகிச்சை பெற்ற மாணவர்கள் வைத்திய சாலையை விந்து வெளியிட்டனர், ref:  மாணவ குழு மோதல் எதிரொலி சிகிச்சை பெற்ற மாணவர்கள் வைத்தியசாலையை விட்டு வெளியேறினர்\n",
      "ctc_wer: 0.30909091234207153\n"
     ]
    }
   ],
   "source": [
    "def inference(batch, lang_id):\n",
    "    signal, signal_len, transcript, transcript_len = batch\n",
    "    encoded, encoded_len = model.forward(input_signal=batch[0], input_signal_length=batch[1])\n",
    "\n",
    "    language_ids = [lang_id] * len(batch[0])\n",
    "        \n",
    "    # wer.update(\n",
    "    #                 predictions=encoded,\n",
    "    #                 predictions_lengths=encoded_len,\n",
    "    #                 targets=transcript,\n",
    "    #                 targets_lengths=transcript_len,\n",
    "    #             )\n",
    "\n",
    "    \n",
    "    # whatthis, scores, training_batch_wer_1 = wer.compute()\n",
    "    # print(f\"wer: {training_batch_wer_1}\")\n",
    "    # print(f\"whatthis: {whatthis}\")\n",
    "    # print(f\"scores: {scores}\")\n",
    "    \n",
    "    decoder, target_length, states = model.decoder(targets=transcript, target_length=transcript_len)\n",
    "\n",
    "    loss_value, training_batch_wer_2, _, _ = model.joint(\n",
    "                encoder_outputs=encoded,\n",
    "                decoder_outputs=decoder,\n",
    "                encoder_lengths=encoded_len,\n",
    "                transcripts=transcript,\n",
    "                transcript_lengths=transcript_len,\n",
    "                compute_wer=True,\n",
    "                language_ids=language_ids\n",
    "            )\n",
    "    \n",
    "    print(f\"loss_value: {loss_value}\")\n",
    "    print(f\"training_batch_wer_2: {training_batch_wer_2}\")\n",
    "    \n",
    "    log_probs = model.ctc_decoder(encoder_output=encoded, language_ids=language_ids)\n",
    "            \n",
    "    model.ctc_wer.update(\n",
    "                        predictions=log_probs,\n",
    "                        targets=transcript,\n",
    "                        targets_lengths=transcript_len,\n",
    "                        predictions_lengths=encoded_len,\n",
    "                        lang_ids=language_ids,\n",
    "                    )\n",
    "    \n",
    "    ctc_wer, _, _ = model.ctc_wer.compute()\n",
    "    model.ctc_wer.reset()\n",
    "    print(f\"ctc_wer: {ctc_wer}\")\n",
    "\n",
    "model.cur_decoder = \"ctc\" ## rnnt\n",
    "\n",
    "inference(batch, 'ta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-04-17 01:37:31 nemo_logging:349] /home/frozenwolf/Desktop/indiai/NeMo/nemo/collections/asr/parts/preprocessing/features.py:417: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "      with torch.cuda.amp.autocast(enabled=False):\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores: 0.0 hyp:  சீமான் மீதான புகார் குறித்து நடிகை விஜயலட்சுமி வீட்டில் போலீஸ் விசாரணை, ref:  சீமான் மீதான புகார் குறித்து நடிகை விஜயலட்சுமி வீட்டில் போலீஸ் விசாரணை\n",
      "scores: 0.2727272727272727 hyp:  தேர்தல் காலத்தில் தேர்தலுக்கு முன்பாக தேர்தலின் போது மற்றும் தேர்தல் நடந்து முடிந்ததன் தீர்மான அறிக்கையிடலின், ref:  தேர்தல் காலத்தில் தேர்தலுக்கு முன்பாக தேர்தலின்போது மற்றும் தேர்தல் நடந்து முடிந்ததன் பின்னரான அறிக்கையிடலின்\n",
      "scores: 0.2857142857142857 hyp:  அமைச்சரவை பதவியேற்ற பின் யார் யாருக்கு என்றாக்கா என்பது குறித்த தகவல்கள் வெளிவரும் என்பது குறிப்பிடத்தக்கது, ref:  அமைச்சரவை பதவி ஏற்ற பின் யார் யாருக்கு எந்த இலாகா என்பது குறித்த தகவல்கள் வெளிவரும் என்பது குறிப்பிடத்தக்கது\n",
      "scores: 0.2222222222222222 hyp:  ஒரு படிமம் இன்னொன்றில் விட்டு போனதையே நிறைக்கிறது என எனக்கும் இப்போது படுகிறது, ref:  ஒரு படிமம் இன்னொன்றில் விட்டுப்போனதை நிறைக்கிறது என எனக்கும் இப்போது படுகிறது\n",
      "scores: 0.1 hyp:  பரவன்மலை ரயில் நிலையம் அருகே நிறுத்தி வைக்கப்பட்டிருந்த காவலரின் இருசக்கர வாகனம் திருட்டு, ref:  பரங்கிமலை ரயில் நிலையம் அருகே நிறுத்தி வைக்கப்பட்டிருந்த காவலரின் இருசக்கர வாகனம் திருட்டு\n",
      "scores: 0.5384615384615384 hyp:  அம்பிகா பைக்கோவை என்ற தமிழ்நூலை பிற்காலத்தில் கம்பனுடனும் சொன்னுடனும் இணைத்து கதைகள் புனைந்து கொண்டார்கள் என்று ஊகிப்பதே சரியாக இருக்கும், ref:  அம்பிகாபதிக்கோவை என்ற தமிழ்நூலைப் பிற்காலத்தில் கம்பனுடனும் சோழனுடனும் இணைத்துக் கதைகள் புனைந்துகொண்டார்கள் என்று ஊகிப்பதே சரியாக இருக்கும்\n",
      "scores: 0.08333333333333333 hyp:  பாகிஸ்தானில் உள்ள கராச்சி பகுதியில் வெயிலின் தாக்கம் அதிகமாக இருப்பதால் சிறுவனின் முகத்தில் தண்ணீர் அடிக்கப்படுகின்றது, ref:  பாகிஸ்தானில் உள்ள கராச்சி பகுதியில் வெயிலின் தாக்கம் அதிகமாக இருப்பதால் சிறுவனின் முகத்தில் தண்ணீர் அடிக்கப்படிகின்றது\n",
      "scores: 0.3333333333333333 hyp:  தாத்தா சாகிப் பால்கே விருது பெற்ற இயக்குனர் பாலச்சந்தருக்கு கருணாநிதி வாழ்த்து, ref:  தாதா சாகேப் பால்கே விருது பெற்ற இயக்குனர் பாலசந்தருக்கு கருணாநிதி வாழ்த்து\n",
      "scores: 0.15384615384615385 hyp:  புற்றுநோய்க்காக சிகிச்சை பெறும் மாணவியை பார்ப்பதற்காக லண்டன் சென்றிருந்த பாகிஸ்தான் முன்னாள் பிரதமர் நவாஸ் ஷெரீப் மற்றும், ref:  புற்றுநோய்க்காக சிகிச்சை பெறும் மனைவியை பார்ப்பதற்காக லண்டன் சென்றிருந்த பாகிஸ்தான் முன்னாள் பிரதமர் நவாஸ் ஷெரிப் மற்றும்\n",
      "scores: 0.1 hyp:  மாணவ குழு மோதல் எதிரொலி சிகிச்சை பெற்ற மாணவர்கள் வைத்தியசாலையில் விட்டு வெளியேறினர், ref:  மாணவ குழு மோதல் எதிரொலி சிகிச்சை பெற்ற மாணவர்கள் வைத்தியசாலையை விட்டு வெளியேறினர்\n",
      "loss_value: 10.711934089660645\n",
      "training_batch_wer_2: 0.2041548192501068\n",
      "scores: 0.0 hyp:  சீமான் மீதான புகார் குறித்து நடிகை விஜயலட்சுமி வீட்டில் போலீஸ் விசாரணை, ref:  சீமான் மீதான புகார் குறித்து நடிகை விஜயலட்சுமி வீட்டில் போலீஸ் விசாரணை\n",
      "scores: 0.2727272727272727 hyp:  தேர்தல் காலத்தில் தேர்தலுக்கு முன்பாக தேர்தலின் போது மற்றும் தேர்தல் நடந்து முடிந்ததன் திறான அறிக்கையிடலின், ref:  தேர்தல் காலத்தில் தேர்தலுக்கு முன்பாக தேர்தலின்போது மற்றும் தேர்தல் நடந்து முடிந்ததன் பின்னரான அறிக்கையிடலின்\n",
      "scores: 0.35714285714285715 hyp:  அமைச்சரை பதவியேற்ற பின் யார் யாருக்கு என் தலாக்கா என்பது குறித்த தகவல்கள் வெளிவரும் என்பது குறிப்பிடத்தக்கது, ref:  அமைச்சரவை பதவி ஏற்ற பின் யார் யாருக்கு எந்த இலாகா என்பது குறித்த தகவல்கள் வெளிவரும் என்பது குறிப்பிடத்தக்கது\n",
      "scores: 0.3333333333333333 hyp:  ஒரு படிமம் இன்னொன்ற விட்ட போனதையே நிறைக்கிறது என எனக்கும் இப்போது படுகிறது, ref:  ஒரு படிமம் இன்னொன்றில் விட்டுப்போனதை நிறைக்கிறது என எனக்கும் இப்போது படுகிறது\n",
      "scores: 0.2 hyp:  பரவைன்மலை ரயில் நிலையம் அருகே தத்தி வைக்கப்பட்டிருந்த காவலரின் இருசக்கர வாகனம் திருட்டு, ref:  பரங்கிமலை ரயில் நிலையம் அருகே நிறுத்தி வைக்கப்பட்டிருந்த காவலரின் இருசக்கர வாகனம் திருட்டு\n",
      "scores: 0.6153846153846154 hyp:  அம்பிகா பிக்கோவை என்ற தழ்நூலை பிற்காலத்தில் கம்பனுடனும் சசனுடனும் இணைத்து கதையில் புனைந்து கொண்டார்கள் என்று ஊகிப்பதே சரியாக இருக்கும், ref:  அம்பிகாபதிக்கோவை என்ற தமிழ்நூலைப் பிற்காலத்தில் கம்பனுடனும் சோழனுடனும் இணைத்துக் கதைகள் புனைந்துகொண்டார்கள் என்று ஊகிப்பதே சரியாக இருக்கும்\n",
      "scores: 0.08333333333333333 hyp:  பாகிஸ்தானில் உள்ள கராச்சி பகுதியில் வெயிலின் தாக்கம் அதிகமாக இருப்பதால் சிறுவனின் முகத்தில் தண்ணீர் அடிக்கப்படுகின்றிறது, ref:  பாகிஸ்தானில் உள்ள கராச்சி பகுதியில் வெயிலின் தாக்கம் அதிகமாக இருப்பதால் சிறுவனின் முகத்தில் தண்ணீர் அடிக்கப்படிகின்றது\n",
      "scores: 0.3333333333333333 hyp:  தாத்தா சஹி பால்கே விருது பெற்ற இயக்குனர் பாலச்சந்தருக்கு கருணாநிதி வாழ்த்து, ref:  தாதா சாகேப் பால்கே விருது பெற்ற இயக்குனர் பாலசந்தருக்கு கருணாநிதி வாழ்த்து\n",
      "scores: 0.15384615384615385 hyp:  புற்றுநோய்க்காக சிகிச்சை பெறும் மாணவியை பார்ப்பதற்காக லண்டன் சென்றிருந்த பாகிஸ்தான் முன்னாள் பிரதமர் நவாஸ் ஷெரீப் மற்றும், ref:  புற்றுநோய்க்காக சிகிச்சை பெறும் மனைவியை பார்ப்பதற்காக லண்டன் சென்றிருந்த பாகிஸ்தான் முன்னாள் பிரதமர் நவாஸ் ஷெரிப் மற்றும்\n",
      "scores: 0.5 hyp:  மாணவ குழு மோதில் எதிரொலியி சிச்ச பெற்ற மாணவர்கள் வைத்திய சாலைய விட்டு வெளியேறினர், ref:  மாணவ குழு மோதல் எதிரொலி சிகிச்சை பெற்ற மாணவர்கள் வைத்தியசாலையை விட்டு வெளியேறினர்\n",
      "ctc_wer: 0.290909081697464\n"
     ]
    }
   ],
   "source": [
    "model.cur_decoder = \"rnnt\" ## rnnt\n",
    "\n",
    "inference(batch, 'ta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cfg.decoder['multisoftmax']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WER: 0.5555555555555556\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def wer(gt: str, pred: str) -> float:\n",
    "    gt_words = gt.strip().split()\n",
    "    pred_words = pred.strip().split()\n",
    "    n = len(gt_words)\n",
    "    \n",
    "    # Initialize matrix\n",
    "    dp = np.zeros((len(gt_words) + 1, len(pred_words) + 1), dtype=int)\n",
    "    \n",
    "    for i in range(len(gt_words) + 1):\n",
    "        dp[i][0] = i\n",
    "    for j in range(len(pred_words) + 1):\n",
    "        dp[0][j] = j\n",
    "\n",
    "    # Fill in the matrix\n",
    "    for i in range(1, len(gt_words) + 1):\n",
    "        for j in range(1, len(pred_words) + 1):\n",
    "            if gt_words[i - 1] == pred_words[j - 1]:\n",
    "                dp[i][j] = dp[i - 1][j - 1]\n",
    "            else:\n",
    "                substitute = dp[i - 1][j - 1] + 1\n",
    "                insert = dp[i][j - 1] + 1\n",
    "                delete = dp[i - 1][j] + 1\n",
    "                dp[i][j] = min(substitute, insert, delete)\n",
    "\n",
    "    wer_result = dp[len(gt_words)][len(pred_words)] / n if n > 0 else 0.0\n",
    "    return wer_result\n",
    "\n",
    "pred = \"ஒரு படிமம் இன்னொன்றை எட்டு போதையை நிறைக்கிறது என நடக்கும் போது படுகிறது\"\n",
    "gt = \"ஒரு படிமம் இன்னொன்றில் விட்டுப்போனதை நிறைக்கிறது என எனக்கும் இப்போது படுகிறது\"\n",
    "\n",
    "print(\"WER:\", wer(gt, pred))  # Output: 0.25 (1 deletion out of 4 words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores: 0.5555555555555556 hyp: ஒரு படிமம் இன்னொன்றை எட்டு போதையை நிறைக்கிறது என நடக்கும் போது படுகிறது, ref: ஒரு படிமம் இன்னொன்றில் விட்டுப்போனதை நிறைக்கிறது என எனக்கும் இப்போது படுகிறது\n",
      "wer: 0.5555555555555556\n"
     ]
    }
   ],
   "source": [
    "import editdistance\n",
    "\n",
    "hypotheses, references = [pred], [gt]\n",
    "words = 0\n",
    "scores = 0\n",
    "for h, r in zip(hypotheses, references):\n",
    "    h_list = h.split()\n",
    "    r_list = r.split()\n",
    "    words += len(r_list)\n",
    "    # Compute Levenstein's distance\n",
    "    print(f\"scores: {editdistance.eval(h_list, r_list)/len(r_list)} hyp: {h}, ref: {r}\")\n",
    "    \n",
    "    scores += editdistance.eval(h_list, r_list)\n",
    "\n",
    "print(f\"wer: {scores/words}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s][NeMo W 2025-04-17 01:37:33 nemo_logging:349] /home/frozenwolf/Desktop/indiai/NeMo/nemo/collections/asr/parts/preprocessing/features.py:417: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "      with torch.cuda.amp.autocast(enabled=False):\n",
      "    \n",
      "Transcribing: 100%|██████████| 1/1 [00:01<00:00,  1.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([' சீமான் மீதான புகார் குறித்து நடிகை விஜயலட்சுமி வீட்டில் போலீஸ் விசாரணை', ' தேர்தல் காலத்தில் தேர்தலுக்கு முன்பாக தேர்தலின் போது மற்றும் தேர்தல் நடந்து முடிந்ததன் பின்னரான அறிக்கையிடலின்', ' அமைச்சரவை பதவியேற்ற பின் யார் யாருக்கு எந்த இலாகா என்பது குறித்த தகவல்கள் வெளிவரும் என்பது குறிப்பிடத்தக்கது', ' ஒரு படிமம் இன்னொன்றில் விட்டுப்போனதை நிறைக்கிறது என எனக்கும் இப்போது படுகிறது', ' பரங்கிமலை ரயில் நிலையம் அருகே நிறுத்தி வைக்கப்பட்டிருந்த காவலரின் இருசக்கர வாகனம் திருட்டு', ' அம்பிகாபதிக்கோவை என்ற தமிழ் நூலை பிற்காலத்தில் கம்பனுடனும் சோழனுடனும் இணைத்து கதைகள் புனைந்து கொண்டார்கள் என்று ஊகிப்பதே சரியாக இருக்கும்', ' பாகிஸ்தானில் உள்ள கராச்சி பகுதியில் வெயிலின் தாக்கம் அதிகமாக இருப்பதால் சிறுவனின் முகத்தில் தண்ணீர் அடிக்கப்படுகின்றது', ' தாத்தா சாஹே பால்கே விருது பெற்ற இயக்குனர் பாலச்சந்தருக்கு கருணாநிதி வாழ்த்து', ' புற்றுநோய்க்காக சிகிச்சை பெறும் மாணவியை பார்ப்பதற்காக லண்டன் சென்றிருந்த பாகிஸ்தான் முன்னாள் பிரதமர் நவாஸ் ஷெரீப் மற்றும்', ' மாணவ குழு மோதல் எதிரொலி சிகிச்சை பெற்ற மாணவர்கள் வைத்தியசாலையை விட்டு வெளியேறினர்'], [' சீமான் மீதான புகார் குறித்து நடிகை விஜயலட்சுமி வீட்டில் போலீஸ் விசாரணை', ' தேர்தல் காலத்தில் தேர்தலுக்கு முன்பாக தேர்தலின் போது மற்றும் தேர்தல் நடந்து முடிந்ததன் பின்னரான அறிக்கையிடலின்', ' அமைச்சரவை பதவியேற்ற பின் யார் யாருக்கு எந்த இலாகா என்பது குறித்த தகவல்கள் வெளிவரும் என்பது குறிப்பிடத்தக்கது', ' ஒரு படிமம் இன்னொன்றில் விட்டுப்போனதை நிறைக்கிறது என எனக்கும் இப்போது படுகிறது', ' பரங்கிமலை ரயில் நிலையம் அருகே நிறுத்தி வைக்கப்பட்டிருந்த காவலரின் இருசக்கர வாகனம் திருட்டு', ' அம்பிகாபதிக்கோவை என்ற தமிழ் நூலை பிற்காலத்தில் கம்பனுடனும் சோழனுடனும் இணைத்து கதைகள் புனைந்து கொண்டார்கள் என்று ஊகிப்பதே சரியாக இருக்கும்', ' பாகிஸ்தானில் உள்ள கராச்சி பகுதியில் வெயிலின் தாக்கம் அதிகமாக இருப்பதால் சிறுவனின் முகத்தில் தண்ணீர் அடிக்கப்படுகின்றது', ' தாத்தா சாஹே பால்கே விருது பெற்ற இயக்குனர் பாலச்சந்தருக்கு கருணாநிதி வாழ்த்து', ' புற்றுநோய்க்காக சிகிச்சை பெறும் மாணவியை பார்ப்பதற்காக லண்டன் சென்றிருந்த பாகிஸ்தான் முன்னாள் பிரதமர் நவாஸ் ஷெரீப் மற்றும்', ' மாணவ குழு மோதல் எதிரொலி சிகிச்சை பெற்ற மாணவர்கள் வைத்தியசாலையை விட்டு வெளியேறினர்'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.cur_decoder = \"rnnt\"\n",
    "rnn_text = model.transcribe(audio[:10], batch_size=10,logprobs=True, language_id='ta')\n",
    "print(rnn_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred:  சீமான் மீதான புகார் குறித்து நடிகை விஜயலட்சுமி வீட்டில் போலீஸ் விசாரணை\n",
      "GT: சீமான் மீதான புகார் குறித்து நடிகை விஜயலட்சுமி வீட்டில் போலீஸ் விசாரணை\n",
      "WER: 0.0\n",
      "\n",
      "\n",
      "Pred:  தேர்தல் காலத்தில் தேர்தலுக்கு முன்பாக தேர்தலின் போது மற்றும் தேர்தல் நடந்து முடிந்ததன் பின்னரான அறிக்கையிடலின்\n",
      "GT: தேர்தல் காலத்தில் தேர்தலுக்கு முன்பாக தேர்தலின்போது மற்றும் தேர்தல் நடந்து முடிந்ததன் பின்னரான அறிக்கையிடலின்\n",
      "WER: 0.18181818181818182\n",
      "\n",
      "\n",
      "Pred:  அமைச்சரவை பதவியேற்ற பின் யார் யாருக்கு எந்த இலாகா என்பது குறித்த தகவல்கள் வெளிவரும் என்பது குறிப்பிடத்தக்கது\n",
      "GT: அமைச்சரவை பதவி ஏற்ற பின் யார் யாருக்கு எந்த இலாகா என்பது குறித்த தகவல்கள் வெளிவரும் என்பது குறிப்பிடத்தக்கது\n",
      "WER: 0.14285714285714285\n",
      "\n",
      "\n",
      "Pred:  ஒரு படிமம் இன்னொன்றில் விட்டுப்போனதை நிறைக்கிறது என எனக்கும் இப்போது படுகிறது\n",
      "GT: ஒரு படிமம் இன்னொன்றில் விட்டுப்போனதை நிறைக்கிறது என எனக்கும் இப்போது படுகிறது\n",
      "WER: 0.0\n",
      "\n",
      "\n",
      "Pred:  பரங்கிமலை ரயில் நிலையம் அருகே நிறுத்தி வைக்கப்பட்டிருந்த காவலரின் இருசக்கர வாகனம் திருட்டு\n",
      "GT: பரங்கிமலை ரயில் நிலையம் அருகே நிறுத்தி வைக்கப்பட்டிருந்த காவலரின் இருசக்கர வாகனம் திருட்டு\n",
      "WER: 0.0\n",
      "\n",
      "\n",
      "Pred:  அம்பிகாபதிக்கோவை என்ற தமிழ் நூலை பிற்காலத்தில் கம்பனுடனும் சோழனுடனும் இணைத்து கதைகள் புனைந்து கொண்டார்கள் என்று ஊகிப்பதே சரியாக இருக்கும்\n",
      "GT: அம்பிகாபதிக்கோவை என்ற தமிழ்நூலைப் பிற்காலத்தில் கம்பனுடனும் சோழனுடனும் இணைத்துக் கதைகள் புனைந்துகொண்டார்கள் என்று ஊகிப்பதே சரியாக இருக்கும்\n",
      "WER: 0.38461538461538464\n",
      "\n",
      "\n",
      "Pred:  பாகிஸ்தானில் உள்ள கராச்சி பகுதியில் வெயிலின் தாக்கம் அதிகமாக இருப்பதால் சிறுவனின் முகத்தில் தண்ணீர் அடிக்கப்படுகின்றது\n",
      "GT: பாகிஸ்தானில் உள்ள கராச்சி பகுதியில் வெயிலின் தாக்கம் அதிகமாக இருப்பதால் சிறுவனின் முகத்தில் தண்ணீர் அடிக்கப்படிகின்றது\n",
      "WER: 0.08333333333333333\n",
      "\n",
      "\n",
      "Pred:  தாத்தா சாஹே பால்கே விருது பெற்ற இயக்குனர் பாலச்சந்தருக்கு கருணாநிதி வாழ்த்து\n",
      "GT: தாதா சாகேப் பால்கே விருது பெற்ற இயக்குனர் பாலசந்தருக்கு கருணாநிதி வாழ்த்து\n",
      "WER: 0.3333333333333333\n",
      "\n",
      "\n",
      "Pred:  புற்றுநோய்க்காக சிகிச்சை பெறும் மாணவியை பார்ப்பதற்காக லண்டன் சென்றிருந்த பாகிஸ்தான் முன்னாள் பிரதமர் நவாஸ் ஷெரீப் மற்றும்\n",
      "GT: புற்றுநோய்க்காக சிகிச்சை பெறும் மனைவியை பார்ப்பதற்காக லண்டன் சென்றிருந்த பாகிஸ்தான் முன்னாள் பிரதமர் நவாஸ் ஷெரிப் மற்றும்\n",
      "WER: 0.15384615384615385\n",
      "\n",
      "\n",
      "Pred:  மாணவ குழு மோதல் எதிரொலி சிகிச்சை பெற்ற மாணவர்கள் வைத்தியசாலையை விட்டு வெளியேறினர்\n",
      "GT: மாணவ குழு மோதல் எதிரொலி சிகிச்சை பெற்ற மாணவர்கள் வைத்தியசாலையை விட்டு வெளியேறினர்\n",
      "WER: 0.0\n",
      "\n",
      "\n",
      "Avg WER: 0.12798035298035298\n"
     ]
    }
   ],
   "source": [
    "avg_score = 0\n",
    "for pred, gt in zip(rnn_text[0], trasncripts):\n",
    "    print(f\"Pred: {pred}\")\n",
    "    print(f\"GT: {gt}\")\n",
    "    print(f\"WER: {wer(gt, pred)}\")\n",
    "    avg_score += wer(gt, pred)\n",
    "    print(\"\\n\")\n",
    "    \n",
    "print(f\"Avg WER: {avg_score/len(rnn_text[0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s][NeMo W 2025-04-17 01:37:35 nemo_logging:349] /home/frozenwolf/Desktop/indiai/NeMo/nemo/collections/asr/parts/preprocessing/features.py:417: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "      with torch.cuda.amp.autocast(enabled=False):\n",
      "    \n",
      "Transcribing: 100%|██████████| 1/1 [00:01<00:00,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([' சீமான் மீதான புகார் குறித்து நடிகை விஜயலட்சுமி வீட்டில் போலீஸ் விசாரணை', ' தேர்தல் காலத்தில் தேர்தலுக்கு முன்பாக தேர்தலின் போது மற்றும் தேர்தல் நடந்து முடிந்ததன் பின்னரான அறிக்கையிடலின்', ' அமைச்சரவை பதவியேற்ற பின் யார் யாருக்கு எந்த இலாகா என்பது குறித்த தகவல்கள் வெளிவரும் என்பது குறிப்பிடத்தக்கது', ' ஒரு படிமம் இன்னொன்றில் விட்டுப்போனதைே நிறைக்கிறது என எனக்கும் இப்போது படுகிறது', ' பரங்கிமலை ரயில் நிலையம் அருகே நிறுத்தி வைக்கப்பட்டிருந்த காவலரின் இருசக்கர வாகனம் திருட்டு', ' அம்பிகாபதிக்கோவை என்ற தமிழ்நூலை பிற்காலத்தில் கம்பனுடனும் சோழனுடனும் இணைத்து கதைகள் புனைந்து கொண்டார்கள் என்று ஊகிப்பதே சரியாக இருக்கும்', ' பாகிஸ்தானில் உள்ள கராச்சி பகுதியில் வெயிலின் தாக்கம் அதிகமாக இருப்பதால் சிறுவனின் முகத்தில் தண்ணீர் அடிக்கப்படுகின்றது', ' த தாாதா சஹே பால்கே விருது பெற்ற இயக்குனர் பாலச்சந்தருக்கு கருணாநிதி வாழ்த்து', ' புற்றுநோய்க்காக சிகிச்சை பெறும் மாணவியை பார்ப்பதற்காக லண்டன் சென்றிருந்த பாகிஸ்தான் முன்னாள் பிரதமர் நவாஸ் ஷெரீப் மற்றும்', ' மாணவ குழு மோதல் எதிரொலி சிகிச்சை பெற்ற மாணவர்கள் வைத்தியசாலையை விட்டு வெளியேறினர்'], [' சீமான் மீதான புகார் குறித்து நடிகை விஜயலட்சுமி வீட்டில் போலீஸ் விசாரணை', ' தேர்தல் காலத்தில் தேர்தலுக்கு முன்பாக தேர்தலின் போது மற்றும் தேர்தல் நடந்து முடிந்ததன் பின்னரான அறிக்கையிடலின்', ' அமைச்சரவை பதவியேற்ற பின் யார் யாருக்கு எந்த இலாகா என்பது குறித்த தகவல்கள் வெளிவரும் என்பது குறிப்பிடத்தக்கது', ' ஒரு படிமம் இன்னொன்றில் விட்டுப்போனதைே நிறைக்கிறது என எனக்கும் இப்போது படுகிறது', ' பரங்கிமலை ரயில் நிலையம் அருகே நிறுத்தி வைக்கப்பட்டிருந்த காவலரின் இருசக்கர வாகனம் திருட்டு', ' அம்பிகாபதிக்கோவை என்ற தமிழ்நூலை பிற்காலத்தில் கம்பனுடனும் சோழனுடனும் இணைத்து கதைகள் புனைந்து கொண்டார்கள் என்று ஊகிப்பதே சரியாக இருக்கும்', ' பாகிஸ்தானில் உள்ள கராச்சி பகுதியில் வெயிலின் தாக்கம் அதிகமாக இருப்பதால் சிறுவனின் முகத்தில் தண்ணீர் அடிக்கப்படுகின்றது', ' த தாாதா சஹே பால்கே விருது பெற்ற இயக்குனர் பாலச்சந்தருக்கு கருணாநிதி வாழ்த்து', ' புற்றுநோய்க்காக சிகிச்சை பெறும் மாணவியை பார்ப்பதற்காக லண்டன் சென்றிருந்த பாகிஸ்தான் முன்னாள் பிரதமர் நவாஸ் ஷெரீப் மற்றும்', ' மாணவ குழு மோதல் எதிரொலி சிகிச்சை பெற்ற மாணவர்கள் வைத்தியசாலையை விட்டு வெளியேறினர்'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.cur_decoder = \"ctc\"\n",
    "ctc_text = model.transcribe(audio[:10], batch_size=10,logprobs=False, language_id='ta')\n",
    "print(ctc_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred:  சீமான் மீதான புகார் குறித்து நடிகை விஜயலட்சுமி வீட்டில் போலீஸ் விசாரணை\n",
      "GT: சீமான் மீதான புகார் குறித்து நடிகை விஜயலட்சுமி வீட்டில் போலீஸ் விசாரணை\n",
      "WER: 0.0\n",
      "\n",
      "\n",
      "Pred:  தேர்தல் காலத்தில் தேர்தலுக்கு முன்பாக தேர்தலின் போது மற்றும் தேர்தல் நடந்து முடிந்ததன் பின்னரான அறிக்கையிடலின்\n",
      "GT: தேர்தல் காலத்தில் தேர்தலுக்கு முன்பாக தேர்தலின்போது மற்றும் தேர்தல் நடந்து முடிந்ததன் பின்னரான அறிக்கையிடலின்\n",
      "WER: 0.18181818181818182\n",
      "\n",
      "\n",
      "Pred:  அமைச்சரவை பதவியேற்ற பின் யார் யாருக்கு எந்த இலாகா என்பது குறித்த தகவல்கள் வெளிவரும் என்பது குறிப்பிடத்தக்கது\n",
      "GT: அமைச்சரவை பதவி ஏற்ற பின் யார் யாருக்கு எந்த இலாகா என்பது குறித்த தகவல்கள் வெளிவரும் என்பது குறிப்பிடத்தக்கது\n",
      "WER: 0.14285714285714285\n",
      "\n",
      "\n",
      "Pred:  ஒரு படிமம் இன்னொன்றில் விட்டுப்போனதைே நிறைக்கிறது என எனக்கும் இப்போது படுகிறது\n",
      "GT: ஒரு படிமம் இன்னொன்றில் விட்டுப்போனதை நிறைக்கிறது என எனக்கும் இப்போது படுகிறது\n",
      "WER: 0.1111111111111111\n",
      "\n",
      "\n",
      "Pred:  பரங்கிமலை ரயில் நிலையம் அருகே நிறுத்தி வைக்கப்பட்டிருந்த காவலரின் இருசக்கர வாகனம் திருட்டு\n",
      "GT: பரங்கிமலை ரயில் நிலையம் அருகே நிறுத்தி வைக்கப்பட்டிருந்த காவலரின் இருசக்கர வாகனம் திருட்டு\n",
      "WER: 0.0\n",
      "\n",
      "\n",
      "Pred:  அம்பிகாபதிக்கோவை என்ற தமிழ்நூலை பிற்காலத்தில் கம்பனுடனும் சோழனுடனும் இணைத்து கதைகள் புனைந்து கொண்டார்கள் என்று ஊகிப்பதே சரியாக இருக்கும்\n",
      "GT: அம்பிகாபதிக்கோவை என்ற தமிழ்நூலைப் பிற்காலத்தில் கம்பனுடனும் சோழனுடனும் இணைத்துக் கதைகள் புனைந்துகொண்டார்கள் என்று ஊகிப்பதே சரியாக இருக்கும்\n",
      "WER: 0.3076923076923077\n",
      "\n",
      "\n",
      "Pred:  பாகிஸ்தானில் உள்ள கராச்சி பகுதியில் வெயிலின் தாக்கம் அதிகமாக இருப்பதால் சிறுவனின் முகத்தில் தண்ணீர் அடிக்கப்படுகின்றது\n",
      "GT: பாகிஸ்தானில் உள்ள கராச்சி பகுதியில் வெயிலின் தாக்கம் அதிகமாக இருப்பதால் சிறுவனின் முகத்தில் தண்ணீர் அடிக்கப்படிகின்றது\n",
      "WER: 0.08333333333333333\n",
      "\n",
      "\n",
      "Pred:  த தாாதா சஹே பால்கே விருது பெற்ற இயக்குனர் பாலச்சந்தருக்கு கருணாநிதி வாழ்த்து\n",
      "GT: தாதா சாகேப் பால்கே விருது பெற்ற இயக்குனர் பாலசந்தருக்கு கருணாநிதி வாழ்த்து\n",
      "WER: 0.4444444444444444\n",
      "\n",
      "\n",
      "Pred:  புற்றுநோய்க்காக சிகிச்சை பெறும் மாணவியை பார்ப்பதற்காக லண்டன் சென்றிருந்த பாகிஸ்தான் முன்னாள் பிரதமர் நவாஸ் ஷெரீப் மற்றும்\n",
      "GT: புற்றுநோய்க்காக சிகிச்சை பெறும் மனைவியை பார்ப்பதற்காக லண்டன் சென்றிருந்த பாகிஸ்தான் முன்னாள் பிரதமர் நவாஸ் ஷெரிப் மற்றும்\n",
      "WER: 0.15384615384615385\n",
      "\n",
      "\n",
      "Pred:  மாணவ குழு மோதல் எதிரொலி சிகிச்சை பெற்ற மாணவர்கள் வைத்தியசாலையை விட்டு வெளியேறினர்\n",
      "GT: மாணவ குழு மோதல் எதிரொலி சிகிச்சை பெற்ற மாணவர்கள் வைத்தியசாலையை விட்டு வெளியேறினர்\n",
      "WER: 0.0\n",
      "\n",
      "\n",
      "Avg WER: 0.1425102675102675\n"
     ]
    }
   ],
   "source": [
    "avg_score = 0\n",
    "for pred, gt in zip(ctc_text[0], trasncripts):\n",
    "    print(f\"Pred: {pred}\")\n",
    "    print(f\"GT: {gt}\")\n",
    "    print(f\"WER: {wer(gt, pred)}\")\n",
    "    avg_score += wer(gt, pred)\n",
    "    print(\"\\n\")\n",
    "    \n",
    "print(f\"Avg WER: {avg_score/len(rnn_text[0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s][NeMo W 2025-04-17 01:37:36 nemo_logging:349] /home/frozenwolf/Desktop/indiai/NeMo/nemo/collections/asr/parts/preprocessing/features.py:417: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "      with torch.cuda.amp.autocast(enabled=False):\n",
      "    \n",
      "Transcribing: 100%|██████████| 1/1 [00:01<00:00,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total WER (ctc): 0.1455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.14545454545454545"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import editdistance\n",
    "\n",
    "def compute_wer(model, audio, gt_texts, decoder=\"rnnt\", language_id=\"en\", verbose=True):\n",
    "    assert decoder in [\"rnnt\", \"ctc\"], \"Decoder must be 'rnnt' or 'ctc'\"\n",
    "    model.cur_decoder = decoder\n",
    "\n",
    "    # Transcribe using model\n",
    "    predictions = model.transcribe(audio, batch_size=len(audio), logprobs=(decoder == \"rnnt\"), language_id=language_id)[0]\n",
    "\n",
    "    total_words = 0\n",
    "    total_errors = 0\n",
    "\n",
    "    for pred, gt in zip(predictions, gt_texts):\n",
    "        hyp_words = pred.strip().split()\n",
    "        ref_words = gt.strip().split()\n",
    "\n",
    "        errors = editdistance.eval(hyp_words, ref_words)\n",
    "        total_errors += errors\n",
    "        total_words += len(ref_words)\n",
    "\n",
    "        if verbose:\n",
    "            wer = errors / len(ref_words) if ref_words else 0.0\n",
    "            print(f\"WER: {wer:.3f} | Pred: {pred} | Ref: {gt}\")\n",
    "\n",
    "    final_wer = total_errors / total_words if total_words else 0.0\n",
    "    print(f\"\\nTotal WER ({decoder}): {final_wer:.4f}\")\n",
    "    return final_wer\n",
    "\n",
    "\n",
    "compute_wer(model, audio[:10], trasncripts, decoder=\"ctc\", language_id=\"ta\", verbose=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "indiaai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
